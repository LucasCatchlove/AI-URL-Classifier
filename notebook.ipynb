{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ofmPaJBG6bL"
      },
      "source": [
        "#**Casting the Net:  Machine Learning for Phishing Website Detection**\n",
        "\n",
        "##Abstract \n",
        "\n",
        "The goal of the project was to train a series of models to classify URLs as legimitimate or fraudulent (URLs that lead to phishing scams) and provide insights into the classification process. Decision Trees, Random Forests, and Neural networks were used as models while feature importances provided understanding as to how the model classifies samples. The Decision Tree and Random Forest models performed well with accuracies between 95% and 100%; The Neural Network implementation did not perform as well with accuracies maxing out at around 76%. Feature importance analysis revealed that certain features and feature categories played far more important roles in classifiying the URLs. Specifically, the structure of the filename and its associated directory in the URL as well as the information pertaining to the website, namely the hostname TTL, number of redirects, the time it took for the domain to be activated, etc.\n",
        "\n",
        "##Introduction\n",
        "\n",
        "Phishing is a common source of fraud on the internet that can have\n",
        "devastating effects on the lives of its victims. The goal of this project is to\n",
        "produce a model that can quickly identify whether or not a URL presented to a\n",
        "user is malicious as well as provide an intuitive understanding as to why the\n",
        "URL in question is malicious (or not) by extracting insights from the model by examining feature importance (only performed on decision tree and random forest models in this report).  The dataset used is composed of **88,647**\n",
        "training examples with **111 features** in total (the features are categorised into\n",
        "implicit groups that correspond to specific parts of a URLs anatomy such as\n",
        "the domain or protocol). \n",
        "recall, and confusion matrices will be used to evaluate the performance of the\n",
        "model. The main challenges will likely revolve around extracting meaningful\n",
        "insights from the trained model using the previously mentioned techniques;\n",
        "their respective implementations are likely to give way to unforeseen\n",
        "challenges that will need to be dealt with.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Experimental Setup**"
      ],
      "metadata": {
        "id": "a8gJT7O1qkNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Experimental Results**"
      ],
      "metadata": {
        "id": "AIccwx2Uqvyo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMtFJDI0Jg19"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import sklearn.ensemble\n",
        "import sklearn.inspection\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.inspection import permutation_importance\n",
        "!pip install shap \n",
        "import shap\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOMFCyk5d7n2"
      },
      "source": [
        "##Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://data.mendeley.com/datasets/72ptz43s9v/1\n",
        "\n",
        "Total number of instances: 88,647 \\\\\n",
        "Number of legitimate website instances (labeled as 0): 58,000 \\\\\n",
        "Number of phishing website instances (labeled as 1): 30,647 \\\\\n",
        "Total number of features: 111 \\\\\n",
        "\n",
        "train size = 62052 samples (70% of dataset) \\\\\n",
        "test size = 26595 samples (30% of the dataset)\n",
        "\n",
        "**why use a imbalanced dataset?**\n",
        "\n",
        "Due to the fact that most websites are legitimate rather than fraudulent, the imbalance reflects the reality of the problem space. While the code below can be configured to use a balanced or imbalanced dataset, the model performs better when the imbalanced dataset is used. "
      ],
      "metadata": {
        "id": "ASmd6bxE8ZVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('dataset_full.csv')\n",
        "\n",
        "feature_names = list(dataset.columns.values)[:111]\n",
        "num_features = len(feature_names)\n",
        "\n",
        "X, y = dataset.iloc[:,0:111], dataset['phishing']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "#creation of validation sets for use with feature permutation\n",
        "X_train, X_vali, y_train, y_vali = train_test_split(X_train, y_train, test_size=0.2)\n",
        "\n",
        "#Conversion to PyTorch Tensors for use with the Neural Network implementation \n",
        "X_train_torch = torch.Tensor(X_train.values)\n",
        "y_train_torch = torch.Tensor(y_train.values).long()\n",
        "\n",
        "X_test_torch = torch.Tensor(X_test.values)\n",
        "y_test_torch = torch.Tensor(y_test.values).long()"
      ],
      "metadata": {
        "id": "qxlrLXofHgl_"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PoE35_se_LW"
      },
      "source": [
        "#**Decision Tree Implementation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgOnWav4fEvQ",
        "outputId": "8b15f2bb-7353-4636-d811-738190a8eaaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100.00% training accuracy\n",
            "0.00% training error\n",
            "95.08% test accuracy\n",
            "4.92% test error\n"
          ]
        }
      ],
      "source": [
        "tree = sklearn.tree.DecisionTreeClassifier(random_state=0).fit(X_train, y_train);\n",
        "\n",
        "y_pred = tree.predict(X_train)\n",
        "\n",
        "training_accuracy = sklearn.metrics.accuracy_score(y_train, y_pred)\n",
        "\n",
        "y_pred = tree.predict(X_test)\n",
        "\n",
        "test_accuracy = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "print('{:.2%} training accuracy'.format(training_accuracy))\n",
        "print('{:.2%} training error'.format(1-training_accuracy))\n",
        "print('{:.2%} test accuracy'.format(test_accuracy))\n",
        "print('{:.2%} test error'.format(1-test_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature Importances"
      ],
      "metadata": {
        "id": "cSohYpeF2GyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Mean Decrease In Impurity (MDI)"
      ],
      "metadata": {
        "id": "15XK5UNKTlyo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdu5CE1ffnkf"
      },
      "outputs": [],
      "source": [
        "importances = tree.feature_importances_\n",
        "std = np.std([tree.feature_importances_], axis=0)\n",
        "tree_importances = pd.Series(importances, index=feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(20,40)\n",
        "tree_importances.plot.barh(yerr=std, ax=ax, align='center')\n",
        "plt.title(\"Feature importances using 'Mean Decrease in Impurity (MDI)\")\n",
        "plt.ylabel(\"Mean decrease in impurity\");"
      ],
      "metadata": {
        "id": "Y9yKoTuoPagT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Feature Permutation\n",
        "\n"
      ],
      "metadata": {
        "id": "41a0IAmxJYb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = permutation_importance(tree, X_vali, y_vali, n_repeats=10, random_state=42, n_jobs=-1)\n",
        "importances = result.importances_mean"
      ],
      "metadata": {
        "id": "UgKioYprJeCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,40))\n",
        "plt.barh(range(X.shape[1]), importances, align='center')\n",
        "plt.yticks(range(X.shape[1]), feature_names)\n",
        "plt.title('Feature Importance using Feature Permutation')\n",
        "plt.xlabel('Feature Importance ')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_roiEgbnKVle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.TreeExplainer(tree)\n",
        "shap_values = explainer(X)\n",
        "\n",
        "# shap.initjs()?shap.force_plot(explainer.expected_value[0], shap_values[0], feature_names=feature_names)\n",
        "# shap.summary_plot(shap_values, X_test, class_names=[\"legitimate\", \"phishing\"])\n",
        "shap.plots.beeswarm(shap_values[0], max_display=10, show=False)\n",
        "plt.title(\"SHAP values for diabetes dataset\")\n",
        "plt.xlabel(\"SHAP value\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sM7dI3cjWymv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyg98Ol4dxfO"
      },
      "source": [
        "#**Random Forest Implementation**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgQsUzl15Szr",
        "outputId": "6abda4ec-fce7-4b90-e551-441ccfd731c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100.00% training accuracy\n",
            "0.00% training error\n",
            "96.81% test accuracy\n",
            "3.19% test error\n"
          ]
        }
      ],
      "source": [
        "forest = sklearn.ensemble.RandomForestClassifier(random_state=0).fit(X_train, y_train);\n",
        "\n",
        "y_pred = forest.predict(X_train)\n",
        "\n",
        "training_accuracy = sklearn.metrics.accuracy_score(y_train, y_pred)\n",
        "\n",
        "y_pred = forest.predict(X_test)\n",
        "\n",
        "test_accuracy = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "print('{:.2%} training accuracy'.format(training_accuracy))\n",
        "print('{:.2%} training error'.format(1-training_accuracy))\n",
        "print('{:.2%} test accuracy'.format(test_accuracy))\n",
        "print('{:.2%} test error'.format(1-test_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature Importances"
      ],
      "metadata": {
        "id": "oMsUGfUX3pzm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Mean Decrease in Impurity (MDI)\n"
      ],
      "metadata": {
        "id": "Rxawr5pLT1Be"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "BzDYlZrA5qXV"
      },
      "outputs": [],
      "source": [
        "importances = forest.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
        "forest_importances = pd.Series(importances, index=feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(20,40)\n",
        "forest_importances.plot.barh(yerr=std, ax=ax, align='center')\n",
        "ax.set_title(\"Feature importances using MDI\")\n",
        "ax.set_ylabel(\"Mean decrease in impurity\")"
      ],
      "metadata": {
        "id": "Wi8AQX3rPOqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Feature Permutation"
      ],
      "metadata": {
        "id": "9lt_AJLcM4BA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = permutation_importance(forest, X_vali, y_vali, n_repeats=10, random_state=42, n_jobs=-1)\n",
        "importances = result.importances_mean"
      ],
      "metadata": {
        "id": "BOxN0vwNM7qK"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,40))\n",
        "plt.barh(range(X.shape[1]), importances, align='center')\n",
        "plt.yticks(range(X.shape[1]), feature_names)\n",
        "plt.title('Feature Importance using Feature Permutation')\n",
        "plt.xlabel('Feature Importance ')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BvgGtGpNM8qX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_c9SbtnIdghI"
      },
      "source": [
        "##**Neural Network Implementation**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create batches and shuffle\n",
        "train_dataset = TensorDataset(X_train_torch, y_train_torch)\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#network architecture\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(111, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 384),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(384, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 192),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(192, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 96),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(96, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 48),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(48, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 2),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "#optimizer and loss function with momentum and regularization (weight_decay)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.00005, momentum=0.87)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "#training loop with mini-batching\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        labels = labels.view(-1)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels)\n",
        "        \n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_acc = running_corrects.double() / len(train_dataset)\n",
        "\n",
        "    print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "          .format(epoch+1, num_epochs, epoch_loss, epoch_acc*100))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0frfYqufXTIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**References**\n",
        "\n",
        "Vrbančič, Grega (2020), “Phishing Websites Dataset”, Mendeley Data, V1, doi: 10.17632/72ptz43s9v.1"
      ],
      "metadata": {
        "id": "N4CYM-a1Ue1s"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}